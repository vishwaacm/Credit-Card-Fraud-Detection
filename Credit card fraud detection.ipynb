{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit card Frad dectection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                               Read the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_df = creditcard_df.sample(n=50000, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  See the data content and head lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169876</th>\n",
       "      <td>119907.0</td>\n",
       "      <td>-0.611712</td>\n",
       "      <td>-0.769705</td>\n",
       "      <td>-0.149759</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>2.028577</td>\n",
       "      <td>-2.019887</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>-0.523020</td>\n",
       "      <td>0.358468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075208</td>\n",
       "      <td>0.045536</td>\n",
       "      <td>0.380739</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>-2.220686</td>\n",
       "      <td>-0.201146</td>\n",
       "      <td>0.066501</td>\n",
       "      <td>0.221180</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127467</th>\n",
       "      <td>78340.0</td>\n",
       "      <td>-0.814682</td>\n",
       "      <td>1.319219</td>\n",
       "      <td>1.329415</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.284871</td>\n",
       "      <td>-0.653985</td>\n",
       "      <td>0.321552</td>\n",
       "      <td>0.435975</td>\n",
       "      <td>-0.704298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128619</td>\n",
       "      <td>-0.368565</td>\n",
       "      <td>0.090660</td>\n",
       "      <td>0.401147</td>\n",
       "      <td>-0.261034</td>\n",
       "      <td>0.080621</td>\n",
       "      <td>0.162427</td>\n",
       "      <td>0.059456</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137900</th>\n",
       "      <td>82382.0</td>\n",
       "      <td>-0.318193</td>\n",
       "      <td>1.118618</td>\n",
       "      <td>0.969864</td>\n",
       "      <td>-0.127052</td>\n",
       "      <td>0.569563</td>\n",
       "      <td>-0.532484</td>\n",
       "      <td>0.706252</td>\n",
       "      <td>-0.064966</td>\n",
       "      <td>-0.463271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.305402</td>\n",
       "      <td>-0.774704</td>\n",
       "      <td>-0.123884</td>\n",
       "      <td>-0.495687</td>\n",
       "      <td>-0.018148</td>\n",
       "      <td>0.121679</td>\n",
       "      <td>0.249050</td>\n",
       "      <td>0.092516</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21513</th>\n",
       "      <td>31717.0</td>\n",
       "      <td>-1.328271</td>\n",
       "      <td>1.018378</td>\n",
       "      <td>1.775426</td>\n",
       "      <td>-1.574193</td>\n",
       "      <td>-0.117696</td>\n",
       "      <td>-0.457733</td>\n",
       "      <td>0.681867</td>\n",
       "      <td>-0.031641</td>\n",
       "      <td>0.383872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220815</td>\n",
       "      <td>-0.419013</td>\n",
       "      <td>-0.239197</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.232829</td>\n",
       "      <td>0.814177</td>\n",
       "      <td>0.098797</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>15.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134700</th>\n",
       "      <td>80923.0</td>\n",
       "      <td>1.276712</td>\n",
       "      <td>0.617120</td>\n",
       "      <td>-0.578014</td>\n",
       "      <td>0.879173</td>\n",
       "      <td>0.061706</td>\n",
       "      <td>-1.472002</td>\n",
       "      <td>0.373692</td>\n",
       "      <td>-0.287204</td>\n",
       "      <td>-0.084482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160161</td>\n",
       "      <td>-0.430404</td>\n",
       "      <td>-0.076738</td>\n",
       "      <td>0.258708</td>\n",
       "      <td>0.552170</td>\n",
       "      <td>0.370701</td>\n",
       "      <td>-0.034255</td>\n",
       "      <td>0.041709</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "169876  119907.0 -0.611712 -0.769705 -0.149759 -0.224877  2.028577 -2.019887   \n",
       "127467   78340.0 -0.814682  1.319219  1.329415  0.027273 -0.284871 -0.653985   \n",
       "137900   82382.0 -0.318193  1.118618  0.969864 -0.127052  0.569563 -0.532484   \n",
       "21513    31717.0 -1.328271  1.018378  1.775426 -1.574193 -0.117696 -0.457733   \n",
       "134700   80923.0  1.276712  0.617120 -0.578014  0.879173  0.061706 -1.472002   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "169876  0.292491 -0.523020  0.358468  ... -0.075208  0.045536  0.380739   \n",
       "127467  0.321552  0.435975 -0.704298  ... -0.128619 -0.368565  0.090660   \n",
       "137900  0.706252 -0.064966 -0.463271  ... -0.305402 -0.774704 -0.123884   \n",
       "21513   0.681867 -0.031641  0.383872  ... -0.220815 -0.419013 -0.239197   \n",
       "134700  0.373692 -0.287204 -0.084482  ... -0.160161 -0.430404 -0.076738   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "169876  0.023440 -2.220686 -0.201146  0.066501  0.221180    1.79      0  \n",
       "127467  0.401147 -0.261034  0.080621  0.162427  0.059456    1.98      0  \n",
       "137900 -0.495687 -0.018148  0.121679  0.249050  0.092516    0.89      0  \n",
       "21513   0.009967  0.232829  0.814177  0.098797 -0.004273   15.98      0  \n",
       "134700  0.258708  0.552170  0.370701 -0.034255  0.041709    0.76      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                         To see the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                     Check if any missing data from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169876</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127467</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137900</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21513</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134700</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73392</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103432</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62648</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17527</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203074</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time     V1     V2     V3     V4     V5     V6     V7     V8     V9  \\\n",
       "169876  False  False  False  False  False  False  False  False  False  False   \n",
       "127467  False  False  False  False  False  False  False  False  False  False   \n",
       "137900  False  False  False  False  False  False  False  False  False  False   \n",
       "21513   False  False  False  False  False  False  False  False  False  False   \n",
       "134700  False  False  False  False  False  False  False  False  False  False   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "73392   False  False  False  False  False  False  False  False  False  False   \n",
       "103432  False  False  False  False  False  False  False  False  False  False   \n",
       "62648   False  False  False  False  False  False  False  False  False  False   \n",
       "17527   False  False  False  False  False  False  False  False  False  False   \n",
       "203074  False  False  False  False  False  False  False  False  False  False   \n",
       "\n",
       "        ...    V21    V22    V23    V24    V25    V26    V27    V28  Amount  \\\n",
       "169876  ...  False  False  False  False  False  False  False  False   False   \n",
       "127467  ...  False  False  False  False  False  False  False  False   False   \n",
       "137900  ...  False  False  False  False  False  False  False  False   False   \n",
       "21513   ...  False  False  False  False  False  False  False  False   False   \n",
       "134700  ...  False  False  False  False  False  False  False  False   False   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...     ...   \n",
       "73392   ...  False  False  False  False  False  False  False  False   False   \n",
       "103432  ...  False  False  False  False  False  False  False  False   False   \n",
       "62648   ...  False  False  False  False  False  False  False  False   False   \n",
       "17527   ...  False  False  False  False  False  False  False  False   False   \n",
       "203074  ...  False  False  False  False  False  False  False  False   False   \n",
       "\n",
       "        Class  \n",
       "169876  False  \n",
       "127467  False  \n",
       "137900  False  \n",
       "21513   False  \n",
       "134700  False  \n",
       "...       ...  \n",
       "73392   False  \n",
       "103432  False  \n",
       "62648   False  \n",
       "17527   False  \n",
       "203074  False  \n",
       "\n",
       "[50000 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                        Another way fo checking missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                 For more information of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94568.237120</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>-0.006388</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>-0.013584</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>-0.012014</td>\n",
       "      <td>-0.000626</td>\n",
       "      <td>0.009799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>-0.001578</td>\n",
       "      <td>-0.002866</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>-0.003018</td>\n",
       "      <td>88.835696</td>\n",
       "      <td>0.001560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47644.749181</td>\n",
       "      <td>1.944718</td>\n",
       "      <td>1.655675</td>\n",
       "      <td>1.496093</td>\n",
       "      <td>1.415263</td>\n",
       "      <td>1.373212</td>\n",
       "      <td>1.326671</td>\n",
       "      <td>1.207344</td>\n",
       "      <td>1.165860</td>\n",
       "      <td>1.094200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730002</td>\n",
       "      <td>0.724390</td>\n",
       "      <td>0.642273</td>\n",
       "      <td>0.602641</td>\n",
       "      <td>0.519139</td>\n",
       "      <td>0.482751</td>\n",
       "      <td>0.394789</td>\n",
       "      <td>0.300881</td>\n",
       "      <td>255.854804</td>\n",
       "      <td>0.039466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-46.855047</td>\n",
       "      <td>-63.344698</td>\n",
       "      <td>-31.813586</td>\n",
       "      <td>-5.266509</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-23.496714</td>\n",
       "      <td>-26.548144</td>\n",
       "      <td>-33.785407</td>\n",
       "      <td>-8.739670</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.640785</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-30.269720</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-7.025783</td>\n",
       "      <td>-2.534330</td>\n",
       "      <td>-8.260909</td>\n",
       "      <td>-9.617915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53707.250000</td>\n",
       "      <td>-0.912235</td>\n",
       "      <td>-0.606529</td>\n",
       "      <td>-0.887455</td>\n",
       "      <td>-0.842316</td>\n",
       "      <td>-0.707377</td>\n",
       "      <td>-0.765034</td>\n",
       "      <td>-0.562158</td>\n",
       "      <td>-0.206860</td>\n",
       "      <td>-0.634059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227375</td>\n",
       "      <td>-0.541636</td>\n",
       "      <td>-0.162504</td>\n",
       "      <td>-0.357463</td>\n",
       "      <td>-0.317833</td>\n",
       "      <td>-0.325672</td>\n",
       "      <td>-0.071048</td>\n",
       "      <td>-0.053269</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84531.000000</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.058804</td>\n",
       "      <td>0.181288</td>\n",
       "      <td>-0.009739</td>\n",
       "      <td>-0.071339</td>\n",
       "      <td>-0.270534</td>\n",
       "      <td>0.029527</td>\n",
       "      <td>0.023536</td>\n",
       "      <td>-0.041871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030649</td>\n",
       "      <td>0.008707</td>\n",
       "      <td>-0.011542</td>\n",
       "      <td>0.038580</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>-0.049156</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>22.255000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139321.000000</td>\n",
       "      <td>1.319965</td>\n",
       "      <td>0.801407</td>\n",
       "      <td>1.033060</td>\n",
       "      <td>0.748400</td>\n",
       "      <td>0.603720</td>\n",
       "      <td>0.401818</td>\n",
       "      <td>0.558740</td>\n",
       "      <td>0.325839</td>\n",
       "      <td>0.609796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186562</td>\n",
       "      <td>0.530342</td>\n",
       "      <td>0.148253</td>\n",
       "      <td>0.432802</td>\n",
       "      <td>0.350429</td>\n",
       "      <td>0.246083</td>\n",
       "      <td>0.090069</td>\n",
       "      <td>0.076237</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172784.000000</td>\n",
       "      <td>2.411499</td>\n",
       "      <td>17.418649</td>\n",
       "      <td>4.069865</td>\n",
       "      <td>16.715537</td>\n",
       "      <td>34.099309</td>\n",
       "      <td>22.529298</td>\n",
       "      <td>36.677268</td>\n",
       "      <td>19.587773</td>\n",
       "      <td>9.272376</td>\n",
       "      <td>...</td>\n",
       "      <td>22.588989</td>\n",
       "      <td>6.090514</td>\n",
       "      <td>18.946734</td>\n",
       "      <td>3.962197</td>\n",
       "      <td>5.541598</td>\n",
       "      <td>3.155327</td>\n",
       "      <td>11.135740</td>\n",
       "      <td>15.373170</td>\n",
       "      <td>19656.530000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count   50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean    94568.237120      0.009375     -0.006388      0.007932      0.005389   \n",
       "std     47644.749181      1.944718      1.655675      1.496093      1.415263   \n",
       "min         0.000000    -46.855047    -63.344698    -31.813586     -5.266509   \n",
       "25%     53707.250000     -0.912235     -0.606529     -0.887455     -0.842316   \n",
       "50%     84531.000000      0.034600      0.058804      0.181288     -0.009739   \n",
       "75%    139321.000000      1.319965      0.801407      1.033060      0.748400   \n",
       "max    172784.000000      2.411499     17.418649      4.069865     16.715537   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean      -0.013584      0.002138     -0.012014     -0.000626      0.009799   \n",
       "std        1.373212      1.326671      1.207344      1.165860      1.094200   \n",
       "min      -42.147898    -23.496714    -26.548144    -33.785407     -8.739670   \n",
       "25%       -0.707377     -0.765034     -0.562158     -0.206860     -0.634059   \n",
       "50%       -0.071339     -0.270534      0.029527      0.023536     -0.041871   \n",
       "75%        0.603720      0.401818      0.558740      0.325839      0.609796   \n",
       "max       34.099309     22.529298     36.677268     19.587773      9.272376   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean   ...      0.003204      0.002161     -0.001578     -0.002866   \n",
       "std    ...      0.730002      0.724390      0.642273      0.602641   \n",
       "min    ...    -16.640785    -10.933144    -30.269720     -2.836627   \n",
       "25%    ...     -0.227375     -0.541636     -0.162504     -0.357463   \n",
       "50%    ...     -0.030649      0.008707     -0.011542      0.038580   \n",
       "75%    ...      0.186562      0.530342      0.148253      0.432802   \n",
       "max    ...     22.588989      6.090514     18.946734      3.962197   \n",
       "\n",
       "                V25           V26           V27           V28        Amount  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean      -0.000264      0.002758      0.000194     -0.003018     88.835696   \n",
       "std        0.519139      0.482751      0.394789      0.300881    255.854804   \n",
       "min       -7.025783     -2.534330     -8.260909     -9.617915      0.000000   \n",
       "25%       -0.317833     -0.325672     -0.071048     -0.053269      5.900000   \n",
       "50%        0.016487     -0.049156      0.001380      0.010736     22.255000   \n",
       "75%        0.350429      0.246083      0.090069      0.076237     78.000000   \n",
       "max        5.541598      3.155327     11.135740     15.373170  19656.530000   \n",
       "\n",
       "              Class  \n",
       "count  50000.000000  \n",
       "mean       0.001560  \n",
       "std        0.039466  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#        Whole data can be seen by plotting, when you cannot see them by data, So that can see the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(credit_card_df.isnull(),yticklabels= False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unnecessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#     To see the attempts of fraud from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'Not Fraud'), Text(1, 0, 'Fraud')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = sns.countplot(x='Class', data=credit_card_df)\n",
    "target.set_xticklabels(['Not Fraud','Fraud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#You should add comments explaining what you see. For example here you should say that data is very unbalanced.\n",
    "\n",
    "From the above plot, it is clearly very unblanced data. It means fradulant and non-fradulant are very unbalnced eacth other. If this is the case then requires special care when training and splitting the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the attempts of fraud from the data set based on the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    49922\n",
       "1       78\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#             To see any other avriables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50000 entries, 169876 to 203074\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    50000 non-null  float64\n",
      " 1   V1      50000 non-null  float64\n",
      " 2   V2      50000 non-null  float64\n",
      " 3   V3      50000 non-null  float64\n",
      " 4   V4      50000 non-null  float64\n",
      " 5   V5      50000 non-null  float64\n",
      " 6   V6      50000 non-null  float64\n",
      " 7   V7      50000 non-null  float64\n",
      " 8   V8      50000 non-null  float64\n",
      " 9   V9      50000 non-null  float64\n",
      " 10  V10     50000 non-null  float64\n",
      " 11  V11     50000 non-null  float64\n",
      " 12  V12     50000 non-null  float64\n",
      " 13  V13     50000 non-null  float64\n",
      " 14  V14     50000 non-null  float64\n",
      " 15  V15     50000 non-null  float64\n",
      " 16  V16     50000 non-null  float64\n",
      " 17  V17     50000 non-null  float64\n",
      " 18  V18     50000 non-null  float64\n",
      " 19  V19     50000 non-null  float64\n",
      " 20  V20     50000 non-null  float64\n",
      " 21  V21     50000 non-null  float64\n",
      " 22  V22     50000 non-null  float64\n",
      " 23  V23     50000 non-null  float64\n",
      " 24  V24     50000 non-null  float64\n",
      " 25  V25     50000 non-null  float64\n",
      " 26  V26     50000 non-null  float64\n",
      " 27  V27     50000 non-null  float64\n",
      " 28  V28     50000 non-null  float64\n",
      " 29  Amount  50000 non-null  float64\n",
      " 30  Class   50000 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 13.5 MB\n"
     ]
    }
   ],
   "source": [
    "credit_card_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another way of seeing that the data does not contain any missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#      Check and find the data into train and test models - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we have seen data is very unbalanced. Let have look wtih few methods how do we approach and out come."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit_card_df.drop('Class',axis=1)\n",
    "\n",
    "y = credit_card_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgrmodel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgrmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lgrmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[14968     7]\n",
      " [   13    12]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14975\n",
      "           1       0.63      0.48      0.55        25\n",
      "\n",
      "    accuracy                           1.00     15000\n",
      "   macro avg       0.82      0.74      0.77     15000\n",
      "weighted avg       1.00      1.00      1.00     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions))\n",
    "print('Classification Report: \\n', classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Resampling Techniques - Oversampling minority class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separte the features and target\n",
    "X = credit_card_df.drop('Class',axis=1) \n",
    "\n",
    "y = credit_card_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the training data to the orginal data using Pandas\n",
    "X = pd.concat([X_train,y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the minority and majority classes\n",
    "not_fraud = X[X.Class==0]\n",
    "fraud = X[X.Class==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# up sample the minority classes\n",
    "fraud_upsampled = resample(fraud, replace=True,n_samples=len(not_fraud),random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add majority and upsampled minority\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    34942\n",
       "0    34942\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check and how many of them now\n",
    "upsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above, now the data is balanced each other. Time to put this into logistic regressoion and perform.\n",
    "X_train = upsampled.drop('Class',axis=1)\n",
    "y_train = upsampled.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_pred = upsampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[14282   698]\n",
      " [    1    19]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98     14980\n",
      "           1       0.03      0.95      0.05        20\n",
      "\n",
      "    accuracy                           0.95     15000\n",
      "   macro avg       0.51      0.95      0.51     15000\n",
      "weighted avg       1.00      0.95      0.97     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, upsampled_pred))\n",
    "print('Classification Report: \\n', classification_report(y_test, upsampled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is very good improvement by oversampling technique compared to basic logistic regression model. Where, Recall and f1-score \n",
    "# recaching above 90%. Let's check with Undersampling the main data. Can see any improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separte the features and target\n",
    "X = credit_card_df.drop('Class',axis=1) \n",
    "\n",
    "y = credit_card_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the training data to the orginal data using Pandas\n",
    "X = pd.concat([X_train,y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the minority and majority classes\n",
    "not_fraud = X[X.Class==0]\n",
    "fraud = X[X.Class==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample the majority classes\n",
    "not_fraud_downsampled = resample(not_fraud, replace=True,n_samples=len(fraud),random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add minority and downsampled majority\n",
    "downsampled = pd.concat([fraud, not_fraud_downsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    58\n",
       "0    58\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check and how many of them now\n",
    "downsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above, now the data is balanced each other. Time to put this into logistic regressoion and perform.\n",
    "X_train = downsampled.drop('Class',axis=1)\n",
    "y_train = downsampled.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_pred = downsampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[14066   914]\n",
      " [    1    19]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     14980\n",
      "           1       0.02      0.95      0.04        20\n",
      "\n",
      "    accuracy                           0.94     15000\n",
      "   macro avg       0.51      0.94      0.50     15000\n",
      "weighted avg       1.00      0.94      0.97     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, downsampled_pred))\n",
    "print('Classification Report: \\n', classification_report(y_test, downsampled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is seen that Undersampling is not better than Oversampling because, it takes less data points compared to Oversampling.\n",
    "# hence Oversampling will gives us better results. Lets check other techinique which is called synthetic samples. It is \n",
    "# called SMOTE. It uses a nearest neighbors alogrithm tp genrate new and synthetic data to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separte the features and target\n",
    "X = credit_card_df.drop('Class',axis=1) \n",
    "\n",
    "y = credit_card_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTE(random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = smt.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_pred = smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[14549   431]\n",
      " [    2    18]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     14980\n",
      "           1       0.04      0.90      0.08        20\n",
      "\n",
      "    accuracy                           0.97     15000\n",
      "   macro avg       0.52      0.94      0.53     15000\n",
      "weighted avg       1.00      0.97      0.98     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, smote_pred))\n",
    "print('Classification Report: \\n', classification_report(y_test, smote_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE obiviously increased score for recall and f1-score. Much better than Undersampling and are close to \n",
    "# oversampling technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50000 entries, 169876 to 203074\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    50000 non-null  float64\n",
      " 1   V1      50000 non-null  float64\n",
      " 2   V2      50000 non-null  float64\n",
      " 3   V3      50000 non-null  float64\n",
      " 4   V4      50000 non-null  float64\n",
      " 5   V5      50000 non-null  float64\n",
      " 6   V6      50000 non-null  float64\n",
      " 7   V7      50000 non-null  float64\n",
      " 8   V8      50000 non-null  float64\n",
      " 9   V9      50000 non-null  float64\n",
      " 10  V10     50000 non-null  float64\n",
      " 11  V11     50000 non-null  float64\n",
      " 12  V12     50000 non-null  float64\n",
      " 13  V13     50000 non-null  float64\n",
      " 14  V14     50000 non-null  float64\n",
      " 15  V15     50000 non-null  float64\n",
      " 16  V16     50000 non-null  float64\n",
      " 17  V17     50000 non-null  float64\n",
      " 18  V18     50000 non-null  float64\n",
      " 19  V19     50000 non-null  float64\n",
      " 20  V20     50000 non-null  float64\n",
      " 21  V21     50000 non-null  float64\n",
      " 22  V22     50000 non-null  float64\n",
      " 23  V23     50000 non-null  float64\n",
      " 24  V24     50000 non-null  float64\n",
      " 25  V25     50000 non-null  float64\n",
      " 26  V26     50000 non-null  float64\n",
      " 27  V27     50000 non-null  float64\n",
      " 28  V28     50000 non-null  float64\n",
      " 29  Amount  50000 non-null  float64\n",
      " 30  Class   50000 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 13.5 MB\n"
     ]
    }
   ],
   "source": [
    "credit_card_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#           Random Forests model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = credit_card_df.drop('Class',axis=1)\n",
    "\n",
    "#y = credit_card_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest for imbalanced classification\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "                           n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-create the model\n",
    "Random_class = RandomForestClassifier(n_estimators=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "scores = cross_val_score(Random_class, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.896\n"
     ]
    }
   ],
   "source": [
    "# summarize performance\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#     K-nearest neighbours model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "KScaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KScaler.fit(credit_card_df.drop('Class',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaled_feat = KScaler.transform(credit_card_df.drop('Class',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_df_feat = pd.DataFrame(Scaled_feat,columns = credit_card_df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531832</td>\n",
       "      <td>-0.319374</td>\n",
       "      <td>-0.461036</td>\n",
       "      <td>-0.105403</td>\n",
       "      <td>-0.162703</td>\n",
       "      <td>1.487157</td>\n",
       "      <td>-1.524150</td>\n",
       "      <td>0.252213</td>\n",
       "      <td>-0.448081</td>\n",
       "      <td>0.318656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262078</td>\n",
       "      <td>-0.107415</td>\n",
       "      <td>0.059879</td>\n",
       "      <td>0.595263</td>\n",
       "      <td>0.043651</td>\n",
       "      <td>-4.277169</td>\n",
       "      <td>-0.422383</td>\n",
       "      <td>0.167959</td>\n",
       "      <td>0.745143</td>\n",
       "      <td>-0.340219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.340613</td>\n",
       "      <td>-0.423745</td>\n",
       "      <td>0.800652</td>\n",
       "      <td>0.883298</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>-0.197558</td>\n",
       "      <td>-0.494568</td>\n",
       "      <td>0.276283</td>\n",
       "      <td>0.374492</td>\n",
       "      <td>-0.652626</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015194</td>\n",
       "      <td>-0.180581</td>\n",
       "      <td>-0.511782</td>\n",
       "      <td>0.143612</td>\n",
       "      <td>0.670410</td>\n",
       "      <td>-0.502317</td>\n",
       "      <td>0.161291</td>\n",
       "      <td>0.410942</td>\n",
       "      <td>0.207639</td>\n",
       "      <td>-0.339476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.255775</td>\n",
       "      <td>-0.168442</td>\n",
       "      <td>0.679491</td>\n",
       "      <td>0.642969</td>\n",
       "      <td>-0.093581</td>\n",
       "      <td>0.424663</td>\n",
       "      <td>-0.402984</td>\n",
       "      <td>0.594920</td>\n",
       "      <td>-0.055188</td>\n",
       "      <td>-0.432347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268750</td>\n",
       "      <td>-0.422752</td>\n",
       "      <td>-1.072450</td>\n",
       "      <td>-0.190430</td>\n",
       "      <td>-0.817777</td>\n",
       "      <td>-0.034450</td>\n",
       "      <td>0.246342</td>\n",
       "      <td>0.630358</td>\n",
       "      <td>0.317515</td>\n",
       "      <td>-0.343736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.319177</td>\n",
       "      <td>-0.687842</td>\n",
       "      <td>0.618948</td>\n",
       "      <td>1.181418</td>\n",
       "      <td>-1.116116</td>\n",
       "      <td>-0.075817</td>\n",
       "      <td>-0.346639</td>\n",
       "      <td>0.574723</td>\n",
       "      <td>-0.026603</td>\n",
       "      <td>0.341872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413707</td>\n",
       "      <td>-0.306878</td>\n",
       "      <td>-0.581425</td>\n",
       "      <td>-0.369970</td>\n",
       "      <td>0.021294</td>\n",
       "      <td>0.449005</td>\n",
       "      <td>1.680839</td>\n",
       "      <td>0.249765</td>\n",
       "      <td>-0.004172</td>\n",
       "      <td>-0.284757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.286398</td>\n",
       "      <td>0.651688</td>\n",
       "      <td>0.376592</td>\n",
       "      <td>-0.391654</td>\n",
       "      <td>0.617407</td>\n",
       "      <td>0.054828</td>\n",
       "      <td>-1.111168</td>\n",
       "      <td>0.319470</td>\n",
       "      <td>-0.245811</td>\n",
       "      <td>-0.086165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142262</td>\n",
       "      <td>-0.223790</td>\n",
       "      <td>-0.597149</td>\n",
       "      <td>-0.117024</td>\n",
       "      <td>0.434049</td>\n",
       "      <td>1.064147</td>\n",
       "      <td>0.762187</td>\n",
       "      <td>-0.087258</td>\n",
       "      <td>0.148654</td>\n",
       "      <td>-0.344244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  0.531832 -0.319374 -0.461036 -0.105403 -0.162703  1.487157 -1.524150   \n",
       "1 -0.340613 -0.423745  0.800652  0.883298  0.015463 -0.197558 -0.494568   \n",
       "2 -0.255775 -0.168442  0.679491  0.642969 -0.093581  0.424663 -0.402984   \n",
       "3 -1.319177 -0.687842  0.618948  1.181418 -1.116116 -0.075817 -0.346639   \n",
       "4 -0.286398  0.651688  0.376592 -0.391654  0.617407  0.054828 -1.111168   \n",
       "\n",
       "         V7        V8        V9  ...       V20       V21       V22       V23  \\\n",
       "0  0.252213 -0.448081  0.318656  ... -0.262078 -0.107415  0.059879  0.595263   \n",
       "1  0.276283  0.374492 -0.652626  ... -0.015194 -0.180581 -0.511782  0.143612   \n",
       "2  0.594920 -0.055188 -0.432347  ...  0.268750 -0.422752 -1.072450 -0.190430   \n",
       "3  0.574723 -0.026603  0.341872  ...  0.413707 -0.306878 -0.581425 -0.369970   \n",
       "4  0.319470 -0.245811 -0.086165  ... -0.142262 -0.223790 -0.597149 -0.117024   \n",
       "\n",
       "        V24       V25       V26       V27       V28    Amount  \n",
       "0  0.043651 -4.277169 -0.422383  0.167959  0.745143 -0.340219  \n",
       "1  0.670410 -0.502317  0.161291  0.410942  0.207639 -0.339476  \n",
       "2 -0.817777 -0.034450  0.246342  0.630358  0.317515 -0.343736  \n",
       "3  0.021294  0.449005  1.680839  0.249765 -0.004172 -0.284757  \n",
       "4  0.434049  1.064147  0.762187 -0.087258  0.148654 -0.344244  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit_card_df_feat\n",
    "\n",
    "y = credit_card_df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 30)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = knn.predict(X_test.sample(n=15000, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[14973     2]\n",
      " [   11    14]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14975\n",
      "           1       0.88      0.56      0.68        25\n",
      "\n",
      "    accuracy                           1.00     15000\n",
      "   macro avg       0.94      0.78      0.84     15000\n",
      "weighted avg       1.00      1.00      1.00     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix: \\n', confusion_matrix(y_test.sample(n=15000, random_state=1), knn_pred))\n",
    "print('Classification Report: \\n', classification_report(y_test.sample(n=15000, random_state=1), knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  To choose correct K value using elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate=[]\n",
    "\n",
    "# Can increase range for better K\n",
    "# Choose the best K from the plot\n",
    "for i in range (1,20):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    knn_i_pred = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(knn_i_pred!=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To help us to choose the best k by plotting error rate as below. Look for K where it is consistence from the graph \n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,20),error_rate,color='black',linestyle='--',marker='x',markerfacecolor='red',markersize=10)\n",
    "plt.title('@error Rate Vs K value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above plot at k=11 is best to choose as an average either side of data set (between lowest and highest)\n",
    "knn = KNeighborsClassifier(n_neighbors=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=11)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again fit the model\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model\n",
    "knn_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[14973     2]\n",
      " [    9    16]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14975\n",
      "           1       0.89      0.64      0.74        25\n",
      "\n",
      "    accuracy                           1.00     15000\n",
      "   macro avg       0.94      0.82      0.87     15000\n",
      "weighted avg       1.00      1.00      1.00     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Score summary\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, knn_pred))\n",
    "print('Classification Report: \\n', classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Elbow method score improves much better compared standard K Neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Support Vector Machines model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[14975     0]\n",
      " [   17     8]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14975\n",
      "           1       1.00      0.32      0.48        25\n",
      "\n",
      "    accuracy                           1.00     15000\n",
      "   macro avg       1.00      0.66      0.74     15000\n",
      "weighted avg       1.00      1.00      1.00     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, svc_pred))\n",
    "print('Classification Report: \\n', classification_report(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#      Optimisation using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary and fill some parameter for C and gamma on SVC()\n",
    "param_grid = {'C':[0.1,1,10,100],'gamma':[1.0,0.1,0.01,0.001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] C=0.1, gamma=1.0 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. C=0.1, gamma=1.0, total=  12.0s\n",
      "[CV] C=0.1, gamma=1.0 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. C=0.1, gamma=1.0, total=  12.2s\n",
      "[CV] C=0.1, gamma=1.0 ................................................\n",
      "[CV] ................................. C=0.1, gamma=1.0, total=  11.7s\n",
      "[CV] C=0.1, gamma=1.0 ................................................\n",
      "[CV] ................................. C=0.1, gamma=1.0, total=  11.7s\n",
      "[CV] C=0.1, gamma=1.0 ................................................\n",
      "[CV] ................................. C=0.1, gamma=1.0, total=  11.6s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................................. C=0.1, gamma=0.1, total=   4.5s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................................. C=0.1, gamma=0.1, total=   4.2s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................................. C=0.1, gamma=0.1, total=   4.5s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................................. C=0.1, gamma=0.1, total=   4.3s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................................. C=0.1, gamma=0.1, total=   5.1s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=0.1, gamma=0.01, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=0.1, gamma=0.01, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=0.1, gamma=0.01, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=0.1, gamma=0.01, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=0.1, gamma=0.01, total=   0.4s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=0.1, gamma=0.001, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=0.1, gamma=0.001, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=0.1, gamma=0.001, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=0.1, gamma=0.001, total=   0.2s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=0.1, gamma=0.001, total=   0.2s\n",
      "[CV] C=1, gamma=1.0 ..................................................\n",
      "[CV] ................................... C=1, gamma=1.0, total=  59.6s\n",
      "[CV] C=1, gamma=1.0 ..................................................\n",
      "[CV] ................................... C=1, gamma=1.0, total= 1.1min\n",
      "[CV] C=1, gamma=1.0 ..................................................\n",
      "[CV] ................................... C=1, gamma=1.0, total= 1.1min\n",
      "[CV] C=1, gamma=1.0 ..................................................\n",
      "[CV] ................................... C=1, gamma=1.0, total= 1.0min\n",
      "[CV] C=1, gamma=1.0 ..................................................\n",
      "[CV] ................................... C=1, gamma=1.0, total= 1.1min\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................................... C=1, gamma=0.1, total=   9.7s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................................... C=1, gamma=0.1, total=   9.9s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................................... C=1, gamma=0.1, total=   9.5s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................................... C=1, gamma=0.1, total=   9.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................................... C=1, gamma=0.1, total=  10.6s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................................. C=1, gamma=0.01, total=   0.5s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................................. C=1, gamma=0.01, total=   0.6s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................................. C=1, gamma=0.01, total=   0.5s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................................. C=1, gamma=0.01, total=   0.5s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................................. C=1, gamma=0.01, total=   0.5s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................................. C=1, gamma=0.001, total=   0.2s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................................. C=1, gamma=0.001, total=   0.2s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................................. C=1, gamma=0.001, total=   0.2s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................................. C=1, gamma=0.001, total=   0.2s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................................. C=1, gamma=0.001, total=   0.2s\n",
      "[CV] C=10, gamma=1.0 .................................................\n",
      "[CV] .................................. C=10, gamma=1.0, total= 1.3min\n",
      "[CV] C=10, gamma=1.0 .................................................\n",
      "[CV] .................................. C=10, gamma=1.0, total= 1.3min\n",
      "[CV] C=10, gamma=1.0 .................................................\n",
      "[CV] .................................. C=10, gamma=1.0, total= 1.3min\n",
      "[CV] C=10, gamma=1.0 .................................................\n",
      "[CV] .................................. C=10, gamma=1.0, total= 1.3min\n",
      "[CV] C=10, gamma=1.0 .................................................\n",
      "[CV] .................................. C=10, gamma=1.0, total= 1.3min\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................................. C=10, gamma=0.1, total=   7.2s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................................. C=10, gamma=0.1, total=   7.2s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................................. C=10, gamma=0.1, total=   6.9s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................................. C=10, gamma=0.1, total=   6.9s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................................. C=10, gamma=0.1, total=  10.2s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................................. C=10, gamma=0.01, total=   0.5s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................................. C=10, gamma=0.01, total=   0.5s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................................. C=10, gamma=0.01, total=   0.5s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................................. C=10, gamma=0.01, total=   0.5s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................................. C=10, gamma=0.01, total=   0.5s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................................ C=10, gamma=0.001, total=   0.2s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................................ C=10, gamma=0.001, total=   0.3s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................................ C=10, gamma=0.001, total=   0.2s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................................ C=10, gamma=0.001, total=   0.2s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=10, gamma=0.001, total=   0.2s\n",
      "[CV] C=100, gamma=1.0 ................................................\n",
      "[CV] ................................. C=100, gamma=1.0, total= 1.3min\n",
      "[CV] C=100, gamma=1.0 ................................................\n",
      "[CV] ................................. C=100, gamma=1.0, total= 1.2min\n",
      "[CV] C=100, gamma=1.0 ................................................\n",
      "[CV] ................................. C=100, gamma=1.0, total= 1.2min\n",
      "[CV] C=100, gamma=1.0 ................................................\n",
      "[CV] ................................. C=100, gamma=1.0, total= 1.2min\n",
      "[CV] C=100, gamma=1.0 ................................................\n",
      "[CV] ................................. C=100, gamma=1.0, total= 1.3min\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ................................. C=100, gamma=0.1, total=   6.5s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ................................. C=100, gamma=0.1, total=   6.8s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ................................. C=100, gamma=0.1, total=   6.4s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ................................. C=100, gamma=0.1, total=   6.4s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ................................. C=100, gamma=0.1, total=  10.2s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=100, gamma=0.01, total=   0.3s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=100, gamma=0.01, total=   0.4s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=100, gamma=0.01, total=   0.3s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=100, gamma=0.01, total=   0.4s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=100, gamma=0.01, total=   0.4s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=100, gamma=0.001, total=   0.3s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=100, gamma=0.001, total=   0.3s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=100, gamma=0.001, total=   0.3s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=100, gamma=0.001, total=   0.3s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=100, gamma=0.001, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 21.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100],\n",
       "                         'gamma': [1.0, 0.1, 0.01, 0.001]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the CVe object and fit the model\n",
    "grid = GridSearchCV(SVC(),param_grid,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the model\n",
    "grid_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[14974     1]\n",
      " [   12    13]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14975\n",
      "           1       0.93      0.52      0.67        25\n",
      "\n",
      "    accuracy                           1.00     15000\n",
      "   macro avg       0.96      0.76      0.83     15000\n",
      "weighted avg       1.00      1.00      1.00     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explain the summary\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, grid_pred))\n",
    "print('Classification Report: \\n', classification_report(y_test, grid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
